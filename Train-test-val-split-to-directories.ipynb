{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216bbb8c",
   "metadata": {},
   "source": [
    "# Splitting train val test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f4a6989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images:  506\n",
      "Training:  404\n",
      "Validation:  102\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dadfe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# # Creating Train / Val / Test folders (One time use)\n",
    "root_dir = 'D:/Rhaenessa/Github/pytorch-github/Satellite image Classification Dataset-RSI-CB256'\n",
    "\n",
    "# Classes names list\n",
    "yourclasses = ['cloudy','desert','green_area','water']\n",
    "\n",
    "\n",
    "for i in range(len(yourclasses)):\n",
    "    class1 = '/' + yourclasses[i]\n",
    "    os.makedirs(root_dir +'/splitted-data/train' + yourclasses[i])\n",
    "    os.makedirs(root_dir +'/splitted-data/test' + yourclasses[i])\n",
    "    os.makedirs(root_dir +'/splitted-data/val' + yourclasses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd2a0ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "225\n",
      "225\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4b3932301991>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtrain_FileNames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_FileNames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_FileNames\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallFileNames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;31m# train_FileNames, val_FileNames = np.split(np.array(allFileNames),int(len(allFileNames)*0.7))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "# Creating partitions of the data after shuffeling\n",
    "for k in range(len(yourclasses)):\n",
    "    currentCls = yourclasses[i]\n",
    "    src = root_dir +\"/\"+currentCls # Folder to copy images from\n",
    "\n",
    "    allFileNames = os.listdir(src)\n",
    "    np.random.shuffle(allFileNames)\n",
    "    \n",
    "    # int(len(allFileNames)*0.8),int(len(allFileNames)*0.15),int(len(allFileNames)*0.15)\n",
    "    length = int(len(allFileNames)*0.8)\n",
    "    length1 = int(len(allFileNames)*0.15)\n",
    "    length2 = int(len(allFileNames)*0.15)\n",
    "    print(length)\n",
    "    print(length1)\n",
    "    print(length2)\n",
    "    train_FileNames, test_FileNames, val_FileNames =np.split(np.array(allFileNames),[])\n",
    "    # train_FileNames, val_FileNames = np.split(np.array(allFileNames),int(len(allFileNames)*0.7))\n",
    "\n",
    "\n",
    "    train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n",
    "    test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n",
    "    val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n",
    "\n",
    "print('Total images: ', len(allFileNames))\n",
    "print('Training: ', len(train_FileNames))\n",
    "print('Test: ', len(test_FileNames))\n",
    "print('Validation: ', len(val_FileNames))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a051cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Copy-pasting images\n",
    "for name in train_FileNames:\n",
    "    shutil.copy(name, \"sar_new_data/data/train\"+currentCls)\n",
    "\n",
    "for name in val_FileNames:\n",
    "    shutil.copy(name, \"sar_new_data/data/val\"+currentCls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
